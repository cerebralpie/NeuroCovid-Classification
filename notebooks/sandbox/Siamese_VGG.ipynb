{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:28.559786200Z",
     "start_time": "2024-02-15T01:54:28.379671655Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Activation, BatchNormalization,\n",
    "    UpSampling2D, Input, Concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras import backend as K\n",
    "from custom_cnn.Siamese import siamese_model"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:28.609880051Z",
     "start_time": "2024-02-15T01:54:28.570878589Z"
    }
   },
   "id": "47cf2ce949054c3d",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:28.697627215Z",
     "start_time": "2024-02-15T01:54:28.615488402Z"
    }
   },
   "id": "9ddac8f7c09934ac",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:28.791686963Z",
     "start_time": "2024-02-15T01:54:28.682045423Z"
    }
   },
   "id": "d00d57e2072808b4"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:28.813541611Z",
     "start_time": "2024-02-15T01:54:28.751639214Z"
    }
   },
   "id": "dbfbd5e8e9469f86"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48477fc8a27fed1"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-4\n",
    "\n",
    "PATH = \".\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:28.872278429Z",
     "start_time": "2024-02-15T01:54:28.799173859Z"
    }
   },
   "id": "e0c60d4790f2ae1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2fac62a7d1dab17"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def load_data(path, split=0.1):\n",
    "    images = sorted(glob(os.path.join(path, \"images/*\")))\n",
    "    masks = sorted(glob(os.path.join(path, \"masks/*\")))\n",
    "    \n",
    "    total_size = len(images)\n",
    "    valid_size = int(total_size * split)\n",
    "    test_size = int(total_size * split)\n",
    "    \n",
    "    train_x, valid_x = train_test_split(images, test_size=valid_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(masks, test_size=valid_size, random_state=42)\n",
    "    \n",
    "    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:28.901212070Z",
     "start_time": "2024-02-15T01:54:28.876334507Z"
    }
   },
   "id": "e3658b173ee7b0ba"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x / 255.0\n",
    "    \n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x / 255.0\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    \n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:29.005077163Z",
     "start_time": "2024-02-15T01:54:28.904533308Z"
    }
   },
   "id": "2d9f7293746a5822"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the tf.data pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6e57e781fac350c"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
    "    x.set_shape([IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    y.set_shape([IMAGE_SIZE, IMAGE_SIZE, 1])\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def tf_dataset(x, y, batch=BATCH_SIZE):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:29.033313032Z",
     "start_time": "2024-02-15T01:54:28.987670976Z"
    }
   },
   "id": "72ca9871e6bced21"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  264\n",
      "Validation data:  33\n",
      "Testing data:  33\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(PATH)\n",
    "\n",
    "print(\"Training data: \", len(train_x))\n",
    "print(\"Validation data: \", len(valid_x))\n",
    "print(\"Testing data: \", len(test_x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:29.108432006Z",
     "start_time": "2024-02-15T01:54:29.016926908Z"
    }
   },
   "id": "e3e26fe22909b5c",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def read_and_rgb(x):\n",
    "    x = cv2.imread(x)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:29.125688140Z",
     "start_time": "2024-02-15T01:54:29.087666265Z"
    }
   },
   "id": "92969583039193eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f42b0cda2708f956"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "inputs = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name=\"input_image\")\n",
    "encoder = siamese_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:29.304518131Z",
     "start_time": "2024-02-15T01:54:29.114392937Z"
    }
   },
   "id": "4033d33220a87da0"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " model (Functional)          (None, 16)                   525912    ['input_2[0][0]',             \n",
      "                                                                     'input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dot (Dot)                   (None, 1)                    0         ['model[0][0]',               \n",
      "                                                                     'model[1][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 525912 (2.01 MB)\n",
      "Trainable params: 525912 (2.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:29.364010305Z",
     "start_time": "2024-02-15T01:54:29.344163676Z"
    }
   },
   "id": "a581d2c76ed42dac"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "#inputs = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name=\"input_image\")\n",
    "#encoder2 = VGG19(input_tensor=inputs, weights=\"imagenet\", include_top=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:09.878392740Z",
     "start_time": "2024-02-15T01:54:09.846274559Z"
    }
   },
   "id": "30664b637187b4d0"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "#encoder2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:09.957320422Z",
     "start_time": "2024-02-15T01:54:09.885415017Z"
    }
   },
   "id": "c31747234eb773a8"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def model():\n",
    "    siam = siamese_model()\n",
    "\n",
    "    encoder_input = siam.get_layer(\"dot\").output\n",
    "    encoder = VGG19(input_tensor=encoder_input, weights=\"imagenet\", include_top=False)\n",
    "    \n",
    "    # skip_connection_names = [\"input_image\", \"block_1_expand_relu\", \"block_3_expand_relu\", \"block_6_expand_relu\"]\n",
    "    skip_connection_names = [\"input_image\", \"block1_pool\", \"block2_pool\", \"block3_pool\", \"block4_pool\"]\n",
    "    encoder_output = encoder.get_layer(\"block5_pool\").output\n",
    "    #skip_connection_names = [\"input_image\", \"re_lu\", \"re_lu_3\", \"re_lu_7\"]\n",
    "    #encoder_output = encoder.get_layer(\"re_lu_16\").output\n",
    "\n",
    "    f = [16, 32, 48, 64, 80]\n",
    "    x = encoder_output\n",
    "    for i in range(1, len(skip_connection_names)+1, 1):\n",
    "        x_skip = encoder.get_layer(skip_connection_names[-i]).output\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Concatenate()([x, x_skip])\n",
    "\n",
    "        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([siam.get_layer(\"input_2\"), siam.get_layer(\"input_3\")], x)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:09.982760253Z",
     "start_time": "2024-02-15T01:54:09.939156062Z"
    }
   },
   "id": "7cb7ab97cdc88a24"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"block1_conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[60], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n",
      "Cell \u001B[0;32mIn[59], line 5\u001B[0m, in \u001B[0;36mmodel\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m siam \u001B[38;5;241m=\u001B[39m siamese_model()\n\u001B[1;32m      4\u001B[0m encoder_input \u001B[38;5;241m=\u001B[39m siam\u001B[38;5;241m.\u001B[39mget_layer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdot\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39moutput\n\u001B[0;32m----> 5\u001B[0m encoder \u001B[38;5;241m=\u001B[39m \u001B[43mVGG19\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimagenet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_top\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# skip_connection_names = [\"input_image\", \"block_1_expand_relu\", \"block_3_expand_relu\", \"block_6_expand_relu\"]\u001B[39;00m\n\u001B[1;32m      8\u001B[0m skip_connection_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_image\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock1_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock2_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock3_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock4_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/NeuroCovid-Classification/NeuroCovid/lib/python3.11/site-packages/keras/src/applications/vgg19.py:154\u001B[0m, in \u001B[0;36mVGG19\u001B[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001B[0m\n\u001B[1;32m    152\u001B[0m         img_input \u001B[38;5;241m=\u001B[39m input_tensor\n\u001B[1;32m    153\u001B[0m \u001B[38;5;66;03m# Block 1\u001B[39;00m\n\u001B[0;32m--> 154\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mlayers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mConv2D\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrelu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msame\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mblock1_conv1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m    156\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    157\u001B[0m x \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mConv2D(\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;241m64\u001B[39m, (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m), activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m\"\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock1_conv2\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    159\u001B[0m )(x)\n\u001B[1;32m    160\u001B[0m x \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mMaxPooling2D((\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m), strides\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m), name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock1_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m)(x)\n",
      "File \u001B[0;32m~/PycharmProjects/NeuroCovid-Classification/NeuroCovid/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/NeuroCovid-Classification/NeuroCovid/lib/python3.11/site-packages/keras/src/engine/input_spec.py:253\u001B[0m, in \u001B[0;36massert_input_compatibility\u001B[0;34m(input_spec, inputs, layer_name)\u001B[0m\n\u001B[1;32m    251\u001B[0m     ndim \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mrank\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ndim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m ndim \u001B[38;5;241m<\u001B[39m spec\u001B[38;5;241m.\u001B[39mmin_ndim:\n\u001B[0;32m--> 253\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    254\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of layer \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    255\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis incompatible with the layer: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    256\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpected min_ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mspec\u001B[38;5;241m.\u001B[39mmin_ndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    257\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    258\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFull shape received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(shape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    259\u001B[0m         )\n\u001B[1;32m    260\u001B[0m \u001B[38;5;66;03m# Check dtype.\u001B[39;00m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: Input 0 of layer \"block1_conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 1)"
     ]
    }
   ],
   "source": [
    "model = model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T01:54:10.239770550Z",
     "start_time": "2024-02-15T01:54:10.003769143Z"
    }
   },
   "id": "835814936f8685a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e477381f9326821b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.785991571Z"
    }
   },
   "id": "d54d8751b5f42e85",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "smooth = 1e-15\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.786238694Z"
    }
   },
   "id": "c36a2fd32cd94051",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb633d1685b61d74"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = tf_dataset(train_x, train_y, batch=BATCH_SIZE)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.786462545Z"
    }
   },
   "id": "518429ad7a0bc95d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Nadam(LR)\n",
    "metrics = [cdc, bahd]\n",
    "model.compile(loss=cdc_loss, optimizer=opt, metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.786664784Z"
    }
   },
   "id": "d1b02cd3cfe49d6d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.786858028Z"
    }
   },
   "id": "838e3b59a1664270"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_steps = len(train_x) // BATCH_SIZE\n",
    "valid_steps = len(valid_x) // BATCH_SIZE\n",
    "\n",
    "if len(train_x) % BATCH_SIZE != 0:\n",
    "    train_steps += 1\n",
    "if len(valid_x) % BATCH_SIZE != 0:\n",
    "    valid_steps += 1\n",
    "    \n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=valid_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.787258417Z"
    }
   },
   "id": "73083239f48d587d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset = tf_dataset(test_x, test_y, batch=BATCH_SIZE)\n",
    "\n",
    "test_steps = len(test_x) // BATCH_SIZE\n",
    "if len(test_x) % BATCH_SIZE != 0:\n",
    "    test_steps += 1\n",
    "    \n",
    "model.evaluate(test_dataset, steps=test_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.787483090Z"
    }
   },
   "id": "532b0056c5b5b13a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3359fe5102296faf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    x = x/255.0\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.787684089Z"
    }
   },
   "id": "a4757b8538aeb982"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mask_parse(mask):\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = [mask, mask, mask]\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "    return mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.787901363Z"
    }
   },
   "id": "b418951e4678a6fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(test_x[:10], test_y[:10])):\n",
    "    x = read_image(x)\n",
    "    y = read_mask(y)\n",
    "    y_pred = model.predict(np.expand_dims(x, axis=0))[0] > 0.5\n",
    "    h, w, _ = x.shape\n",
    "    white_line = np.ones((h, 10, 3))\n",
    "\n",
    "    all_images = [\n",
    "        x, white_line,\n",
    "        mask_parse(y), white_line,\n",
    "        mask_parse(y_pred)\n",
    "    ]\n",
    "    image = np.concatenate(all_images, axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    a = fig.add_subplot(1, 1, 1)\n",
    "    imgplot = plt.imshow(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.788099847Z"
    }
   },
   "id": "48d8ea77a1967bc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T23:28:06.788295176Z"
    }
   },
   "id": "1e1271395f6054f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
