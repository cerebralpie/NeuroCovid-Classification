{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 21:10:32.772631: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-15 21:10:32.772705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-15 21:10:32.828250: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-15 21:10:32.956968: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-15 21:10:35.706602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import src.metrics as nc_metrics\n",
    "import src.utils as nc_utils\n",
    "import notebooks.sandbox.models as nc_models\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from tensorflow.keras.metrics import Recall, Precision"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T00:10:39.645585742Z",
     "start_time": "2024-02-16T00:10:30.274184725Z"
    }
   },
   "id": "b4be86a0409dcceb",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "strategy = nc_utils.start_session()\n",
    "\n",
    "ROOT_DIR = \".\"\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
    "MASK_DIR = os.path.join(ROOT_DIR, \"masks\")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "LR = 1e-4  # Learning rate\n",
    "EPOCHS = 300\n",
    "\n",
    "smallest_dimension = nc_utils.get_smallest_image_dimension(IMAGE_DIR)\n",
    "\n",
    "#IMAGE_SIZE = smallest_dimension\n",
    "IMAGE_SIZE = 256\n",
    "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "INPUT_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-16T00:10:39.632655814Z"
    }
   },
   "id": "23daf607bf731b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "(x_train_paths, y_train_paths), (x_valid_paths, y_valid_paths), (\n",
    "x_test_paths,\n",
    "y_test_paths) = nc_utils.load_data(\n",
    "    image_directory=IMAGE_DIR,\n",
    "    mask_directory=MASK_DIR,\n",
    "    split=0.1\n",
    ")\n",
    "\n",
    "train_dataset = nc_utils.get_tensorflow_dataset(\n",
    "    image_mask_paths=(x_train_paths, y_train_paths),\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_dataset = nc_utils.get_tensorflow_dataset(\n",
    "    image_mask_paths=(x_valid_paths, y_valid_paths),\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataset = nc_utils.get_tensorflow_dataset(\n",
    "    image_mask_paths=(x_test_paths, y_test_paths),\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "data_aug = nc_utils.get_data_augmentation_pipeline()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "50aefcbf63c532ab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initiating model on GPU\n",
    "with strategy.scope():\n",
    "    model = nc_models.unet_model(input_shape=INPUT_SHAPE, augment_data=True, num_filters=8)\n",
    "    metrics=[Recall(), Precision()]\n",
    "    loss=nc_metrics.cdc_loss\n",
    "    opt=tf.keras.optimizers.Nadam(LR)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "802f65cbcf2d401f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4c758720873bdef8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model.compile(optimizer=opt,\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=5, mode='max',\n",
    "                                         restore_best_weights=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1641caecb5699dea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_steps = len(x_train_paths) // BATCH_SIZE\n",
    "valid_steps = len(x_valid_paths) // BATCH_SIZE\n",
    "\n",
    "if len(x_train_paths) % BATCH_SIZE != 0:\n",
    "    train_steps += 1\n",
    "if len(x_valid_paths) % BATCH_SIZE != 0:\n",
    "    valid_steps += 1\n",
    "\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_dataset,\n",
    "        callbacks=[early_stopping],\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_steps=valid_steps)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f163d4b271463759"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_steps = len(x_test_paths) // BATCH_SIZE\n",
    "if len(x_test_paths) % BATCH_SIZE != 0:\n",
    "    test_steps += 1\n",
    "    \n",
    "model.evaluate(test_dataset, steps=test_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "43c46df0e44f192d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fa4d12baa49c986"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    x = x/255.0\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4f0e49e055848b67"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def mask_parse(mask):\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = [mask, mask, mask]\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "    return mask"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "117575c9f58d1753"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(test_x[:10], test_y[:10])):\n",
    "    x = read_image(x)\n",
    "    y = read_mask(y)\n",
    "    y_pred = model.predict(np.expand_dims(x, axis=0))[0] > 0.5\n",
    "    h, w, _ = x.shape\n",
    "    white_line = np.ones((h, 10, 3))\n",
    "\n",
    "    all_images = [\n",
    "        x, white_line,\n",
    "        mask_parse(y), white_line,\n",
    "        mask_parse(y_pred)\n",
    "    ]\n",
    "    image = np.concatenate(all_images, axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    a = fig.add_subplot(1, 1, 1)\n",
    "    imgplot = plt.imshow(image)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d6790b0190051e9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
